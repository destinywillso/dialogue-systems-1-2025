#+OPTIONS: num:nil
#+TITLE: Lab III. Tuning ASR and TTS

In this lab session you will practice styling TTS output using Speech
Synthesis Markup Language (SSML) and tuning ASR. It is assumed that
you have read the relevant literature on the subject before attempting
to solve the assignments.

|:warning: NB|
#+begin_quote
- For a *VG* point you need to do *either* Part A-VG or Part B-VG. You
  donâ€™t have to do both VG parts.
- If you have problems accessing your Azure account (namely, the
  portal and [[https://speech.microsoft.com/][Speech Studio]]) contact Vlad immediately and we work out
  the solution. In the meanwhile you can team up with your classmate
  and work on the assignment together.
#+end_quote  

For reference:
- Speech Synthesis Markup Language (SSML) Version 1.0, W3C
  Recommendation 7 September 2004,
  http://www.w3.org/TR/speech-synthesis/
- Azure Text-to-Speech: [[https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/index-text-to-speech][Docs]], [[https://speech.microsoft.com/][Speech Studio]] (audio content creation)
- Azure Speech-to-Text: [[https://learn.microsoft.com/en-us/azure/ai-services/speech-service/index-speech-to-text][Docs]], [[https://speech.microsoft.com/][Speech Studio]] (custom speech)

* Part A: Hard cases for Speech Recognition

1) Reflect on the following:
   - Can you think of any names for fictional places, people or objects
     that are not recognized? (Keep your final project in mind!)
   - If not, can you try any scientific names for plants, animals,
     geologic terms, etc., or names for classic musical pieces and
     authors?
   - Did you come across any real locations or people that are also
     just not picked up?
   - Any specific accent you are using that makes words difficult to
     process?
     
2) Write some sample code to test the confidence scores in speech
   recogniton. Take a look at the confidence score with the help of
   XState's Visualizer (or you can log it). How good is it?

3) Think about how this problem could be solved. Why do you think
   recognition falters for the examples that you tried?

4) Write a very brief (half-page) report on your experience with
   ASR for your case-study. Save it as ~Lab3A.md~ in the root directory
   of your project (or ~.txt~ or ~.pdf~, just not a Word document).

** Part A-VG. Azure Custom Speech

1) To solve the problem you will use [[https://learn.microsoft.com/en-us/azure/ai-services/speech-service/custom-speech-overview][Custom Speech]]:
   - You will basically have to provide data, either plain text or
     audio files, to help the recognition process.
   - Train and deploy your model (enable content logging). Note the
     *Endpoint ID*.

2) To test your model:
   - Create a file =dm3.js= which implements a very basic ASR test
     (analogous to =dm.js= in this repository). Add the following to
     your =settings= object:
     #+begin_src javascript
       speechRecognitionEndpointId: "paste your Endpoint ID here",
     #+end_src
   - Now you can test your new ASR model! You will be able to download
     the log files for your model in Custom Speech interface.

3) Extend the your report with the following information:
   - Which new words are now supported and can be tested. Report
     should contain your Endpoint ID.


* Part B: Speech Synthesis Poetry Slam
#+BEGIN_QUOTE
A poetry slam is a competition at which poets read or recite original work (or, more rarely, that of others). These performances are then judged on a numeric scale by previously selected members of the audience. (Wikipedia)
#+END_QUOTE

Your task in this assignment is to use SSML in Azure Audio Content
Creation in order to get an artificial poet to recite the your
favourite poem (just a couple of verses) with a speed and *in "a style"
similar to the way how it is read by an actor* (or by a poet
her/himself).

You can refer to some poetry performance found on YouTube or
elsewhere.

** Part B-VG. 

Take a greater effort and take it to next level. You can experiment
with adding things like styles, custom voices, multiple languages,
background audio etc. [[https://learn.microsoft.com/en-us/azure/ai-services/speech-service/speech-synthesis-markup-voice][See the documentation.]]

Sources for inspiration:
- [[https://www.youtube.com/watch?v=IZYoGj8D8pY][California Dreaming]] (386DX art project).
- [[https://raw.githubusercontent.com/vladmaraev/rasa101/master/withoutme.m4a][Without Me]], by Robert Rhys Thomas in 2019 for this course.
- [[file:media/partC_badguy_voiced.mp3][Bad Guy]], by Fang Yuan in 2020 for this course.

* Submission
In your submission provide:
1) report for Part A (and A-VG).
2) text file with your SSML code (=Code/lab3.txt=); in the beginning of
   the file include the reference to the original performance. If you
   have done Part B-VG, mention that.
3) audio file for Part B (=Code/lab3.mp3=)

These files can be placed in your Github repository.

- *Create a new branch*, name it ~lab3~.
- *Commit* your changes into this branch and *push* them to your
  repository (your fork of this repository)
- *Create a pull request*, the same way you did it for Lab 2. Change the
  title to "Lab 3 submission" (if you want to ask a question about
  your code, use the title "Lab 3 work in progress").
- On Canvas, submit the pull request URL.
